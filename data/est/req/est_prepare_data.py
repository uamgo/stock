import os
import re
import traceback
from datetime import datetime, time
from typing import List
from pathlib import Path
import asyncio
import time

import pandas as pd
import exchange_calendars as xcals
from data.est.req.est_concept import EastmoneyConceptStockFetcher
from data.est.req.est_concept_codes import ConceptStockManager
from data.est.req.est_daily import EastmoneyDailyStockFetcher
from data.est.req.est_minute import EastmoneyMinuteStockFetcher
from data.est.req import est_common

FILTER_WORDS = ['*ST', 'ST', 'é€€å¸‚', 'N', 'L', 'C', 'U', 'bj', 'BJ', '688', '83', '87', '88', '89', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99']
FILTER_PATTERN = re.compile('|'.join(map(re.escape, FILTER_WORDS)), re.IGNORECASE)
DATA_DIR = Path("/tmp/stock/est_prepare_data")
DATA_DIR.mkdir(parents=True, exist_ok=True)

BLACKLIST_PATH = str(DATA_DIR / "blacklist_codes.txt")
MEMBERS_DF_PATH = str(DATA_DIR / "members_df.pkl")

class EstStockPipeline:
    def __init__(self, top_n: int = 20, use_proxy: bool = False):
        self.top_n = top_n
        self.use_proxy = use_proxy
        self.concept_manager = ConceptStockManager()
        self.daily_fetcher = EastmoneyDailyStockFetcher()
        self.minute_fetcher = EastmoneyMinuteStockFetcher()
        # æ·»åŠ ç¼“å­˜ç›®å½•
        self.cache_dir = DATA_DIR / "cache"
        self.cache_dir.mkdir(exist_ok=True)

    async def get_top_n_concepts(self) -> List[str]:
        # æ£€æŸ¥ç¼“å­˜
        concepts_cache_path = self.cache_dir / "top_concepts.pkl"
        if concepts_cache_path.exists():
            mtime = os.path.getmtime(concepts_cache_path)
            # å¦‚æœç¼“å­˜æ–‡ä»¶åœ¨30åˆ†é’Ÿå†…ï¼Œç›´æ¥ä½¿ç”¨
            if (datetime.now().timestamp() - mtime) < 1800:  # 30åˆ†é’Ÿ
                try:
                    cached_df = est_common.load_df_from_file(str(concepts_cache_path))
                    if not cached_df.empty and 'çƒ­åº¦åˆ†æ•°' in cached_df.columns:
                        print(f"ä½¿ç”¨ç¼“å­˜çš„æ¦‚å¿µæ¿å—æ•°æ®ï¼Œç¼“å­˜æ—¶é—´: {datetime.fromtimestamp(mtime).strftime('%H:%M:%S')}")
                        return cached_df.nlargest(self.top_n, "çƒ­åº¦åˆ†æ•°")["ä»£ç "].tolist()
                except Exception as e:
                    print(f"è¯»å–æ¦‚å¿µç¼“å­˜å¤±è´¥: {e}")
        
        fetcher = EastmoneyConceptStockFetcher()
        df = fetcher.fetch_and_save()
        if df is None:
            raise RuntimeError("æœªèƒ½è·å–æ¦‚å¿µæ¿å—æ•°æ®")
        
        # ä½¿ç”¨æ–°çš„4ç»´åº¦è¯„åˆ†ä½“ç³»è®¡ç®—çƒ­åº¦
        print("ğŸ”¥ æ­£åœ¨è®¡ç®—æ¦‚å¿µçƒ­åº¦...")
        df = self.calculate_concept_heat(df)
        
        # ä¿å­˜åˆ°ç¼“å­˜
        try:
            est_common.save_df_to_file(df, str(concepts_cache_path))
        except Exception as e:
            print(f"ä¿å­˜æ¦‚å¿µç¼“å­˜å¤±è´¥: {e}")
        
        # æ˜¾ç¤ºçƒ­åº¦æ’åå‰å‡ å
        top_concepts = df.nlargest(min(5, len(df)), "çƒ­åº¦åˆ†æ•°")
        print("ğŸ“Š çƒ­åº¦æ’åTOP5:")
        for _, concept in top_concepts.iterrows():
            print(f"  {concept['åç§°']:<15} | æ¶¨è·Œ: {concept['æ¶¨è·Œå¹…']:>6.2f}% | çƒ­åº¦: {concept['çƒ­åº¦åˆ†æ•°']:>5.1f}åˆ†")
        
        return df.nlargest(self.top_n, "çƒ­åº¦åˆ†æ•°")["ä»£ç "].tolist()
    
    def calculate_concept_heat(self, df: pd.DataFrame) -> pd.DataFrame:
        """è®¡ç®—æ¦‚å¿µçƒ­åº¦åˆ†æ•°ï¼ˆ4ç»´åº¦è¯„åˆ†ä½“ç³»ï¼‰"""
        import numpy as np
        
        results = []
        
        for _, concept in df.iterrows():
            # 1. æ¿å—æ¶¨è·Œå¹…å¾—åˆ† (40%)
            price_change = concept.get('æ¶¨è·Œå¹…', 0)
            price_score = np.clip((price_change + 10) * 5, 0, 100)
            
            # 2. ä¸»åŠ›èµ„é‡‘å‡€æµå…¥å¾—åˆ† (30%)
            capital_flow = concept.get('f62', 0) / 100000000  # è½¬æ¢ä¸ºäº¿å…ƒ
            capital_score = np.clip(capital_flow * 2 + 50, 0, 100)
            
            # 3. æˆäº¤æ´»è·ƒåº¦å¾—åˆ† (20%)
            volume = abs(concept.get('f66', 0)) / 100000000  # è½¬æ¢ä¸ºäº¿å…ƒ
            volume_score = np.clip(np.log10(volume + 1) * 20, 0, 100)
            
            # 4. æŠ€æœ¯æŒ‡æ ‡å¾—åˆ† (10%) - åŸºäºæŒ¯å¹…
            amplitude = abs(concept.get('f78', 0)) / 1000000
            tech_score = np.clip(amplitude * 5, 0, 100)
            
            # åŠ æƒè®¡ç®—æ€»çƒ­åº¦
            total_heat = (price_score * 0.4 + capital_score * 0.3 + 
                          volume_score * 0.2 + tech_score * 0.1)
            
            # çƒ­åº¦ç­‰çº§
            if total_heat >= 80:
                heat_level = "ç«çƒ­"
            elif total_heat >= 60:
                heat_level = "åçƒ­"
            elif total_heat >= 40:
                heat_level = "æ¸©å’Œ"
            elif total_heat >= 20:
                heat_level = "åå†·"
            else:
                heat_level = "æå†·"
            
            results.append({
                'çƒ­åº¦åˆ†æ•°': round(total_heat, 1),
                'çƒ­åº¦ç­‰çº§': heat_level,
                'ä»·æ ¼å¾—åˆ†': round(price_score, 1),
                'èµ„é‡‘å¾—åˆ†': round(capital_score, 1),
                'æ´»è·ƒåº¦å¾—åˆ†': round(volume_score, 1),
                'æŠ€æœ¯å¾—åˆ†': round(tech_score, 1)
            })
        
        # å°†çƒ­åº¦ä¿¡æ¯æ·»åŠ åˆ°åŸDataFrame
        heat_df = pd.DataFrame(results)
        for col in heat_df.columns:
            df[col] = heat_df[col]
        
        return df

    def get_all_members(self, concept_codes: List[str]) -> pd.DataFrame:
        print(f"æ­£åœ¨è·å– {len(concept_codes)} ä¸ªæ¦‚å¿µçš„æˆåˆ†è‚¡...")
        dfs = []
        for i, code in enumerate(concept_codes):
            if i % 5 == 0:  # æ¯5ä¸ªæ¦‚å¿µæ‰“å°ä¸€æ¬¡è¿›åº¦
                print(f"è¿›åº¦: {i+1}/{len(concept_codes)}")
            df = self.concept_manager.get_concept_df(code)
            if df is not None:
                dfs.append(df)
        
        if not dfs:
            return pd.DataFrame()
        
        all_df = pd.concat(dfs, ignore_index=True)
        print(f"åˆå¹¶å‰æ€»è‚¡ç¥¨æ•°: {len(all_df)}")
        
        # ä½¿ç”¨æ›´å®‰å…¨çš„è¿‡æ»¤æ–¹å¼ï¼Œé¿å…æ­£åˆ™è¡¨è¾¾å¼é”™è¯¯
        filtered_df = all_df.copy()
        
        # é€ä¸ªè¿‡æ»¤æ¡ä»¶ï¼Œé¿å…å¤æ‚çš„æ­£åˆ™è¡¨è¾¾å¼
        for word in FILTER_WORDS:
            if word:  # ç¡®ä¿è¿‡æ»¤è¯ä¸ä¸ºç©º
                filtered_df = filtered_df[
                    ~filtered_df["åç§°"].str.contains(word, case=False, na=False, regex=False)
                    & ~filtered_df["ä»£ç "].str.contains(word, case=False, na=False, regex=False)
                ]
        
        # å»é‡
        filtered_df = filtered_df.drop_duplicates(subset=["ä»£ç "])
        print(f"è¿‡æ»¤åè‚¡ç¥¨æ•°: {len(filtered_df)}")
        return filtered_df

    async def run(self) -> pd.DataFrame:
        if not est_common.need_update(MEMBERS_DF_PATH):
            mtime = os.path.getmtime(MEMBERS_DF_PATH)
            print(f"{MEMBERS_DF_PATH} æ— éœ€æ›´æ–°ï¼Œæ–‡ä»¶æœ€åä¿®æ”¹æ—¶é—´: {datetime.fromtimestamp(mtime).strftime('%Y-%m-%d %H:%M:%S')}")
            return None

        t0 = time.time()
        time_stats = {}

        # è·å–æ¦‚å¿µæ¿å—
        t_start = time.time()
        self.top_n = 10  # å‡å°‘æ¦‚å¿µæ•°é‡ä»¥æé«˜é€Ÿåº¦
        top_concept_codes = await self.get_top_n_concepts()
        t_end = time.time()
        time_stats["è·å–æ¦‚å¿µæ¿å—"] = t_end - t_start
        print("Top N æ¦‚å¿µæ¿å—ä»£ç :", top_concept_codes)

        # æ›´æ–°æ¦‚å¿µæˆåˆ† - å¢åŠ å¹¶å‘æ•°
        t_start = time.time()
        concurrent_count = min(15, self.top_n)  # å¢åŠ å¹¶å‘æ•°
        self.concept_manager.update_all_concepts(
            top_concept_codes, use_proxy_and_concurrent=concurrent_count
        )
        t_end = time.time()
        time_stats["æ›´æ–°æ¦‚å¿µæˆåˆ†"] = t_end - t_start

        # è¿‡æ»¤å¹¶ä¿å­˜æˆåˆ†è‚¡
        t_start = time.time()
        members_df = self.get_all_members(top_concept_codes)
        est_common.save_df_to_file(members_df, MEMBERS_DF_PATH)
        t_end = time.time()
        time_stats["è¿‡æ»¤å¹¶ä¿å­˜æˆåˆ†è‚¡"] = t_end - t_start
        print(f"è¿‡æ»¤åæˆåˆ†è‚¡æ•°é‡: {len(members_df)}ï¼Œå·²ä¿å­˜ members_df åˆ° {MEMBERS_DF_PATH}")
        
        # åªæ˜¾ç¤ºå‰10åªè‚¡ç¥¨ä¿¡æ¯ï¼Œå‡å°‘è¾“å‡ºæ—¶é—´
        display_count = min(10, len(members_df))
        for idx, row in members_df.head(display_count).iterrows():
            print(f"ä»£ç : {row['ä»£ç ']}, åç§°: {row['åç§°']}, è‚¡ä»·: {row['è‚¡ä»·']}")
        if len(members_df) > display_count:
            print(f"... è¿˜æœ‰ {len(members_df) - display_count} åªè‚¡ç¥¨")

        # å¹¶è¡Œæ›´æ–°æ—¥çº¿å’Œåˆ†é’Ÿçº¿æ•°æ®
        if not members_df.empty:
            t_start = time.time()
            # åˆ›å»ºä»»åŠ¡å¹¶å¹¶è¡Œæ‰§è¡Œ
            daily_task = self.update_daily_for_members(members_df, use_proxy_and_concurrent=25)
            minute_task = self.update_minute_for_members(members_df, use_proxy_and_concurrent=25)
            
            # å¹¶è¡Œæ‰§è¡Œæ—¥çº¿å’Œåˆ†é’Ÿçº¿æ›´æ–°
            await asyncio.gather(daily_task, minute_task)
            t_end = time.time()
            time_stats["å¹¶è¡Œæ›´æ–°æ•°æ®"] = t_end - t_start

        # æ‰“å°ä»£ç†ä½¿ç”¨æ¬¡æ•°
        print(f"ä»£ç†ä½¿ç”¨æ¬¡æ•°: {getattr(est_common, 'PROXY_USE_COUNT', 0)}")
        total_time = time.time() - t0
        print("å„é˜¶æ®µè€—æ—¶ç»Ÿè®¡ï¼š")
        for k, v in time_stats.items():
            print(f"{k}: {v:.2f} ç§’")
        print(
            f"æ€»è€—æ—¶: {total_time:.2f} ç§’ | å½“å‰æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}"
        )
        return members_df

    async def update_daily_for_members(self, members_df: pd.DataFrame, period="day", adjust="qfq", use_proxy_and_concurrent=25):
        if members_df is None or members_df.empty:
            print("members_df ä¸ºç©ºï¼Œè·³è¿‡æ—¥çº¿æ›´æ–°")
            return
        secids = [
            f"1.{code}" if str(code).startswith("6") else f"0.{code}"
            for code in members_df["ä»£ç "]
        ]
        print(f"å¼€å§‹æ›´æ–° {len(secids)} åªè‚¡ç¥¨çš„æ—¥çº¿æ•°æ®...")
        self.daily_fetcher.update_all_daily(
            secids, period=period, adjust=adjust, use_proxy_and_concurrent=use_proxy_and_concurrent
        )
        print(f"âœ… å·²æ‰¹é‡æ›´æ–° {len(secids)} åªè‚¡ç¥¨çš„æ—¥çº¿æ•°æ®")

    async def update_minute_for_members(self, members_df: pd.DataFrame, period="1", use_proxy_and_concurrent=25):
        if members_df is None or members_df.empty:
            print("members_df ä¸ºç©ºï¼Œè·³è¿‡åˆ†é’Ÿçº¿æ›´æ–°")
            return
        codes_df = pd.DataFrame({"symbol": members_df["ä»£ç "].tolist()})
        print(f"å¼€å§‹æ›´æ–° {len(codes_df)} åªè‚¡ç¥¨çš„åˆ†é’Ÿæ•°æ®...")
        self.minute_fetcher.update_minute_batch(
            codes_df, period=period, use_proxy_and_concurrent=use_proxy_and_concurrent
        )
        print(f"âœ… å·²æ‰¹é‡æ›´æ–° {len(codes_df)} åªè‚¡ç¥¨çš„åˆ†é’Ÿæ•°æ®")

def load_members_df_from_path() -> pd.DataFrame:
    try:
        return est_common.load_df_from_file(MEMBERS_DF_PATH)
    except Exception as e:
        print(f"è¯»å– {MEMBERS_DF_PATH} å¤±è´¥: {e}")
        return pd.DataFrame()

async def main():
    # æ”¯æŒå¿«é€Ÿæ¨¡å¼å‚æ•°
    import sys
    fast_mode = '--fast' in sys.argv or '-f' in sys.argv
    
    if fast_mode:
        print("ğŸš€ å¯ç”¨å¿«é€Ÿæ¨¡å¼...")
        pipeline = EstStockPipeline(top_n=8)  # å‡å°‘æ¦‚å¿µæ•°é‡
    else:
        pipeline = EstStockPipeline(top_n=10)
    
    await pipeline.run()

if __name__ == "__main__":
    asyncio.run(main())
